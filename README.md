# ğŸ§ AuraBeat â€“ Emotion-Based Music Playback System

AuraBeat is a real-time facial expression recognition system that detects user emotions via webcam and automatically plays music that matches the mood. Designed for responsive, offline-capable environments such as cars or embedded systems, AuraBeat integrates lightweight AI models, a browser-based interface, and offline playlist caching.

---

## ğŸš€ Features

- ğŸ¥ **Webcam-based Emotion Detection** using FER models
- ğŸµ **Emotion-to-Music Mapping** (Valenceâ€“Arousal space)
- ğŸ“± **ReactJS Frontend** for intuitive interaction
- âš¡ **Fast Inference** via TinyCNN and DeepFace (OpenCV/RetinaFace)
- ğŸ’¾ **Offline Caching** of detected emotions and liked tracks
- ğŸ“Š **Admin Panel** to view statistics, emotion trends, and feedback
- ğŸ” **Privacy-friendly** â€“ works without login or cloud sync

---

## ğŸ§  Emotion Recognition Models

| Model                  | Accuracy (%) | FPS (CPU) | Status       |
|------------------------|--------------|-----------|--------------|
| TinyCNN (Custom)       | 54.29        | 11.35     | âœ… Integrated |
| DeepFace (OpenCV)      | 50.00        | 10.62     | âœ… Integrated |
| DeepFace (RetinaFace)  | 42.86        | 0.30      | âœ… Integrated |
| RMN (Simulated)        | 74.10        | 4.70      | ğŸ”„ Planned    |
| ViT-lite (Simulated)   | 71.20        | 1.50      | ğŸ”„ Planned    |

---

## ğŸ§© System Architecture

```plaintext
```
[ Webcam ] 
    â†“
[ Emotion Detection Backend (Flask + TinyCNN) ]
    â†“
[ Emotion â†’ Music Mapper ]
    â†“
[ Frontend Player UI (React) ]
    â†“
[ Audio Playback + User Feedback Storage ]
ğŸ“¸ UI Preview

```
```
## ğŸ› ï¸ How to Run
1. Clone Repository
bash
Copy
git clone https://github.com/yourusername/AuraBeat.git
cd AuraBeat
2. Backend (Python + Flask)
bash
Copy
cd backend
pip install -r requirements.txt
python app.py
3. Frontend (React)
bash
Copy
cd frontend
npm install
npm start
ğŸ“ Folder Structure
css
Copy
AuraBeat/
â”œâ”€â”€ backend/             â† Flask-based emotion detection
â”‚   â”œâ”€â”€ models/          â† TinyCNN & DeepFace models
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ frontend/            â† ReactJS UI
â”‚   â””â”€â”€ src/
â”œâ”€â”€ benchmark/           â† Accuracy and FPS logs
â”œâ”€â”€ figures/             â† Graphs, screenshots, charts
â””â”€â”€ README.md
ğŸ§ª Datasets Used
FER2013 for model training/evaluation

Internal test images for inference benchmarks

ğŸ“ˆ Future Work
Deploy RMN and ViT-lite with GPU acceleration

ONNX.js integration for full browser-side inference

Raspberry Pi deployment with picamera2 and local audio output

Cloud sync for emotion logs and personalized playlists

ğŸ“œ License
MIT License â€“ see LICENSE file.

ğŸ‘¥ Authors
  MA Tiruye

Special thanks to Prof. Foglia and Prof. Prete

```
